def utils, streams, s3_bucket
node {
    checkout scm
    utils = load("utils.groovy")
    streams = load("streams.groovy")
    pod = readFile(file: "manifests/pod.yaml")

    s3_bucket = utils.get_pipeline_annotation('s3-bucket')
}

properties([
    pipelineTriggers([]),
    parameters([
      choice(name: 'STREAM',
             // list devel first so that it's the default choice
             choices: (streams.development + streams.production + streams.mechanical),
             description: 'Fedora CoreOS stream to release'),
      string(name: 'VERSION',
             description: 'Fedora CoreOS version to release',
             defaultValue: '',
             trim: true),
      // Default to true for AWS_REPLICATION because the only case
      // where we are running the job by hand is when we're doing a
      // production release and we want to replicate there. Defaulting
      // to true means there is less opportunity for human error.
      //
      // use a string here because passing booleans via `oc start-build -e`
      // is non-trivial
      choice(name: 'AWS_REPLICATION',
             choices: (['true', 'false']),
             description: 'Force AWS AMI replication'),
      string(name: 'COREOS_ASSEMBLER_IMAGE',
             description: 'Override coreos-assembler image to use',
             defaultValue: "coreos-assembler:master",
             trim: true)
    ])
])

currentBuild.description = "[${params.STREAM}] - ${params.VERSION}"

// substitute the right COSA image into the pod definition before spawning it
pod = pod.replace("COREOS_ASSEMBLER_IMAGE", params.COREOS_ASSEMBLER_IMAGE)

// shouldn't need more than 256Mi for this job
pod = pod.replace("COREOS_ASSEMBLER_MEMORY_REQUEST", "256Mi")

echo "Final podspec: ${pod}"

// use a unique label to force Kubernetes to provision a separate pod per run
def pod_label = "cosa-${UUID.randomUUID().toString()}"

// We just lock here out of an abundance of caution in case somehow two release
// jobs run for the same stream, but that really shouldn't happen. Anyway, if it
// *does*, this makes sure they're run serially.
lock(resource: "release-${params.STREAM}") {
podTemplate(cloud: 'openshift', label: pod_label, yaml: pod) {
    node(pod_label) { container('coreos-assembler') {
        if (params.AWS_REPLICATION == 'true') {
            // Replicate the newly uploaded AMI to other regions. Intentionally
            // split out from the 'Upload AWS' stage to allow for tests to be added
            // at a later date before replicating said image.
            //
            // We have to re-run the coreos-meta-translator as aws-replicate
            // only modifies the meta.json
            stage('Replicate AWS AMI') {
                s3_stream_dir = "${s3_bucket}/prod/streams/${params.STREAM}"
                // TODO: Once buildprep supports pulling specific builds
                // operate on the specific build rather than the most
                // recent build
                utils.shwrap("""
                export AWS_CONFIG_FILE=\${AWS_FCOS_BUILDS_BOT_CONFIG}
                coreos-assembler init https://github.com/coreos/fedora-coreos-config
                coreos-assembler buildprep s3://${s3_stream_dir}/builds
                coreos-assembler aws-replicate --build=${params.VERSION} --log-level=INFO
                git clone https://github.com/coreos/fedora-coreos-releng-automation /var/tmp/fcos-releng
                /var/tmp/fcos-releng/coreos-meta-translator/trans.py --workdir .
                coreos-assembler buildupload --skip-builds-json s3 --acl=public-read ${s3_stream_dir}/builds
                """)
            }
        }

        stage('Publish') {
          // Run plume to publish official builds; This will handle modifying
          // object ACLs, modifying AMI image attributes,
          // and creating/modifying the releases.json metadata index
          utils.shwrap("""
          export AWS_CONFIG_FILE=\${AWS_FCOS_BUILDS_BOT_CONFIG}
          plume release --distro fcos \
              --version ${params.VERSION} \
              --stream ${params.STREAM} \
              --bucket ${s3_bucket}
          """)
        }
    }}
}}
